# Prepare Datasets for ODISE

The dataset preparation of ODISE follows [Detectron2](https://github.com/facebookresearch/detectron2/blob/main/datasets/README.md) and [Mask2Former](https://github.com/facebookresearch/Mask2Former/blob/main/datasets/README.md). 

A dataset can be used by accessing [DatasetCatalog](https://detectron2.readthedocs.io/modules/data.html#detectron2.data.DatasetCatalog)
for its data, or [MetadataCatalog](https://detectron2.readthedocs.io/modules/data.html#detectron2.data.MetadataCatalog) for its metadata (class names, etc).
This document explains how to setup the builtin datasets so they can be used by the above APIs.
[Use Custom Datasets](https://detectron2.readthedocs.io/tutorials/datasets.html) gives a deeper dive on how to use `DatasetCatalog` and `MetadataCatalog`,
and how to add new datasets to them.

ODISE has builtin support for a few datasets.
The datasets are assumed to exist in a directory specified by the environment variable
`DETECTRON2_DATASETS`.
Under this directory, detectron2 will look for datasets in the structure described below, if needed.
```bash
$DETECTRON2_DATASETS/
  ade/
  coco/
  VOCdevkit/
  pascal_ctx_d2/
  pascal_voc_d2/
```

You can set the location for builtin datasets by `export DETECTRON2_DATASETS=/path/to/datasets`.
If left unset, the default is `./datasets` relative to your current working directory.

The [model zoo](../MODEL_ZOO.md)
contains configs and models that use these builtin datasets.


## Expected dataset structure for [COCO](https://cocodataset.org/#download):

```bash
coco/
  annotations/
    instances_{train,val}2017.json
    panoptic_{train,val}2017.json
    captions_{train,val}2017.json
    panoptic_caption_{train,val}2017.json # generated by the script mentioned below 
  {train,val}2017/
    # image files that are mentioned in the corresponding json
  panoptic_{train,val}2017/  # png annotations
  panoptic_semseg_{train,val}2017/  # generated by the script mentioned below
```

Install panopticapi by (automatically done by installing ODISE):
```bash
pip install git+https://github.com/cocodataset/panopticapi.git
```
Then run 
```bash
python datasets/prepare_coco_semantic_annos_from_panoptic_annos.py
``` 
to extract semantic annotations from panoptic annotations (only used for evaluation).

For caption supervised setting, create annotation with caption by running
```bash
python datasets/prepare_coco_caption.py
```


## Expected dataset structure for [ADE20k (A-150)](http://sceneparsing.csail.mit.edu/) and [ADE20k-Full (A-847)](https://groups.csail.mit.edu/vision/datasets/ADE20K/):
```bash
ade/
  ADEChallengeData2016/
    images/
    annotations/
    objectInfo150.txt
    # download instance annotation
    annotations_instance/
    # generated by prepare_ade20k_sem_seg.py
    annotations_detectron2/
    # below are generated by prepare_ade20k_pan_seg.py
    ade20k_panoptic_{train,val}.json
    ade20k_panoptic_{train,val}/
  ADE20K_2021_17_01/
    images/
    images_detectron2/
    annotations_detectron2/
    index_ade20k.pkl
    objects.txt
```

### ADE20k(A-150)
The directory `ADEChallengeData2016/annotations_detectron2` is generated by running `python datasets/prepare_ade20k_sem_seg.py`.

Install panopticapi by:
```bash
pip install git+https://github.com/cocodataset/panopticapi.git
```

Download the instance annotation from http://sceneparsing.csail.mit.edu/:
```bash
wget http://sceneparsing.csail.mit.edu/data/ChallengeData2017/annotations_instance.tar
```

Then, run 
```bash
python datasets/prepare_ade20k_pan_seg.py
```
to combine semantic and instance annotations for panoptic annotations.

### ADE20k-Full(A-847)

The directories `ADE20K_2021_17_01/images_detectron2` and `ADE20K_2021_17_01/annotations_detectron2` are generated by running: 
```bash
python datasets/prepare_ade20k_full_sem_seg.py
```

## Expected dataset structure for [PASCAL Context (PC-59)](https://www.cs.stanford.edu/~roozbeh/pascal-context/), [PASCAL Context Full (PC-459)](https://www.cs.stanford.edu/~roozbeh/pascal-context/) and [PASCAL VOC (PAS-21)](http://host.robots.ox.ac.uk/pascal/VOC/):

```bash
VOCdevkit/
  VOC2012/
    JPEGImages/
    SegmentationClass/
    ImageSets/
      Segmentation/
  VOC2010/
    JPEGImages/
    trainval/
    trainval_merged.json
# generated by prepare_pascal_voc_sem_seg.py
pascal_voc_d2/
  images/
  annotations_pascal21/
# generated by prepare_pascal_ctx_sem_seg.py and prepare_pascal_ctx_full_sem_seg.py
pascal_ctx_d2/
  images/
  annotations_ctx59/
  annotations_ctx459/

```
### PASCAL VOC (PAS-21)

Download the dataset from http://host.robots.ox.ac.uk/pascal/VOC/:
```bash
wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar
```
The directory `pascal_voc_d2` is generated by running `python datasets/prepare_pascal_voc_sem_seg.py`.

### PASCAL Context (PC-59)

Download the dataset from http://host.robots.ox.ac.uk/pascal/VOC/ and annotation from https://www.cs.stanford.edu/~roozbeh/pascal-context/:
```bash
wget http://host.robots.ox.ac.uk/pascal/VOC/voc2010/VOCtrainval_03-May-2010.tar
wget https://codalabuser.blob.core.windows.net/public/trainval_merged.json
```

Install [Detail API](https://github.com/zhanghang1989/detail-api) by:
```bash
pip install scikit-image
pip install git+https://github.com/zhanghang1989/detail-api.git#subdirectory=PythonAPI
```

The directories `pascal_ctx_d2/images` and `pascal_ctx_d2/annotations_ctx59` are generated by running:
```bash
python datasets/prepare_pascal_ctx_sem_seg.py`.
```

### PASCAL Context Full (PC-459)

The directory `pascal_ctx_d2/annotations_ctx459` is generated by running:
```bash
python datasets/prepare_pascal_ctx_full_sem_seg.py`.
```


